{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model training for gesture recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 16:47:01.354243: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-24 16:47:01.612983: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-24 16:47:01.613770: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-24 16:47:02.723081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the list of gesture form the `gesture_list.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none' 'open' 'fist' 'index' 'L']\n"
     ]
    }
   ],
   "source": [
    "# Define which gestures should be detected by the model\n",
    "gesture_list = np.loadtxt(\"gesture_list.csv\", delimiter=',', dtype=str)\n",
    "print(gesture_list)\n",
    "num_gestures = len(gesture_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_filepath = \"dataset.csv\"\n",
    "handedness = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.str_, usecols=(0))\n",
    "y_data_labels = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.str_, usecols=(1))\n",
    "x_data = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.float32, usecols=list(range(2, (21*3)+2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left\n",
      "open\n",
      "(1194, 63)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "print(handedness[0])\n",
    "print(y_data_labels[0])\n",
    "print(x_data.shape)\n",
    "print(x_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 300\n",
      "fist: 394\n",
      "index: 300\n",
      "open: 200\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_data_labels, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "for elem in label_count:\n",
    "    print(f\"{elem}: {label_count[elem]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data: convert to N x 21 x 3 -> normalization -> convert to N x 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_data.shape[0]\n",
    "x_data_tensor = np.zeros((N,21,3))\n",
    "for i in range(N):\n",
    "    for j in range(21):\n",
    "        for k in range(3):\n",
    "            x_data_tensor[i,j,k] = x_data[i, 3*j+k]\n",
    "\n",
    "assert x_data[200,15] == x_data_tensor[200, 5, 0]\n",
    "\n",
    "from custom_model.landmark_normalizer import normalize_landmarks\n",
    "    \n",
    "x_data_normalized = np.zeros_like(x_data)\n",
    "for i, gesture in enumerate(x_data_tensor):\n",
    "    x_data_normalized[i] = normalize_landmarks(gesture, handedness[i]).reshape(-1)\n",
    "    \n",
    "assert x_data_normalized.shape == x_data.shape\n",
    "\n",
    "x_data = x_data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the ID of each gesture. The ID coincides with the row number in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.zeros((y_data_labels.shape[0]))\n",
    "for i, label in enumerate(y_data_labels):\n",
    "    for j, gesture in enumerate(gesture_list):\n",
    "        if label == gesture and gesture in gesture_list:\n",
    "            # \"Substitute\" the label with the gesture id\n",
    "            y_data[i] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y training set: [3. 2. 4. 3. 4. 1. 3. 3. 3. 2. 4. 3. 2. 2. 2. 3. 3. 4. 4. 3. 3. 2. 3. 3.\n",
      " 2. 4. 3. 4. 2. 1. 3. 2. 2. 4. 2. 1. 4. 4. 1. 4. 4. 1. 1. 4. 4. 3. 3. 3.\n",
      " 3. 3. 1. 4. 1. 4. 2. 4. 3. 3. 3. 2. 4. 1. 3. 1. 1. 4. 1. 2. 2. 2. 2. 1.\n",
      " 4. 4. 2. 3. 3. 3. 4. 2. 2. 1. 2. 3. 2. 2. 1. 4. 1. 3. 4. 2. 3. 1. 1. 3.\n",
      " 2. 1. 1. 3. 2. 4. 4. 2. 3. 2. 2. 3. 3. 2. 3. 2. 4. 3. 2. 2. 1. 1. 3. 2.\n",
      " 1. 4. 4. 3. 4. 2. 4. 2. 2. 4. 2. 1. 1. 2. 2. 3. 4. 2. 1. 1. 4. 3. 2. 3.\n",
      " 2. 1. 2. 2. 4. 4. 3. 3. 3. 1. 4. 2. 2. 2. 2. 3. 4. 3. 2. 2. 2. 2. 1. 2.\n",
      " 4. 3. 3. 3. 2. 2. 2. 2. 1. 4. 2. 3. 3. 3. 2. 2. 3. 4. 3. 4. 1. 3. 2. 1.\n",
      " 4. 1. 2. 4. 2. 2. 2. 1. 2. 4. 4. 2. 1. 4. 4. 3. 2. 2. 3. 3. 2. 2. 2. 3.\n",
      " 2. 3. 1. 4. 4. 2. 3. 2. 2. 4. 2. 3. 4. 4. 4. 2. 1. 2. 3. 4. 1. 4. 4. 2.\n",
      " 2. 2. 3. 1. 4. 4. 2. 3. 3. 3. 1. 4. 2. 2. 4. 2. 3. 3. 3. 4. 3. 2. 4. 3.\n",
      " 1. 2. 4. 2. 3. 4. 2. 3. 4. 4. 2. 3. 2. 3. 3. 3. 3. 3. 1. 2. 3. 1. 3. 4.\n",
      " 3. 1. 4. 3. 3. 3. 4. 3. 4. 4. 4. 4. 3. 4. 1. 3. 2. 4. 1. 4. 3. 1. 3. 1.\n",
      " 3. 1. 3. 1. 4. 2. 1. 2. 1. 3. 2. 1. 4. 2. 4. 3. 4. 3. 1. 3. 3. 4. 4. 2.\n",
      " 3. 3. 2. 3. 2. 4. 3. 2. 2. 1. 3. 2. 1. 4. 2. 4. 3. 2. 4. 3. 3. 4. 2. 3.\n",
      " 4. 4. 2. 4. 2. 1. 1. 1. 4. 1. 4. 4. 4. 3. 2. 4. 3. 4. 1. 2. 4. 4. 2. 3.\n",
      " 3. 2. 3. 2. 3. 2. 4. 2. 2. 4. 4. 4. 3. 4. 3. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
      " 2. 1. 1. 2. 4. 3. 4. 2. 2. 4. 4. 4. 1. 3. 2. 3. 3. 4. 4. 3. 3. 2. 3. 3.\n",
      " 2. 2. 1. 1. 1. 4. 2. 2. 2. 3. 4. 2. 3. 4. 2. 1. 4. 3. 2. 4. 2. 4. 4. 3.\n",
      " 3. 4. 4. 4. 2. 4. 2. 3. 4. 3. 4. 2. 4. 1. 4. 2. 2. 2. 3. 2. 4. 1. 2. 1.\n",
      " 4. 2. 3. 3. 4. 2. 3. 4. 4. 2. 3. 4. 3. 3. 3. 3. 3. 1. 4. 2. 4. 3. 2. 4.\n",
      " 4. 2. 2. 4. 4. 4. 2. 2. 1. 4. 4. 2. 2. 1. 4. 4. 1. 2. 3. 4. 3. 3. 2. 2.\n",
      " 1. 4. 2. 3. 4. 2. 1. 4. 3. 2. 4. 2. 1. 2. 3. 2. 1. 2. 2. 2. 4. 3. 2. 4.\n",
      " 2. 3. 4. 2. 3. 2. 4. 2. 1. 4. 2. 2. 3. 2. 1. 2. 4. 2. 4. 2. 2. 3. 3. 3.\n",
      " 2. 1. 2. 4. 4. 2. 2. 2. 3. 3. 3. 2. 3. 1. 4. 3. 4. 2. 2. 3. 4. 4. 4. 1.\n",
      " 4. 3. 2. 1. 2. 2. 2. 3. 3. 4. 3. 3. 2. 1. 2. 1. 1. 4. 2. 4. 3. 1. 4. 1.\n",
      " 4. 2. 1. 4. 1. 3. 3. 2. 2. 2. 3. 1. 4. 2. 4. 2. 2. 1. 2. 3. 4. 3. 1. 4.\n",
      " 2. 4. 3. 2. 3. 3. 1. 4. 2. 2. 3. 1. 4. 3. 1. 4. 2. 4. 1. 1. 1. 3. 4. 2.\n",
      " 3. 4. 4. 3. 1. 4. 3. 2. 4. 4. 2. 3. 3. 4. 2. 3. 3. 1. 2. 2. 3. 2. 3. 4.\n",
      " 4. 1. 2. 2. 4. 3. 1. 1. 4. 1. 2. 4. 1. 4. 2. 2. 4. 4. 2. 4. 4. 1. 3. 2.\n",
      " 4. 3. 1. 2. 3. 3. 1. 3. 3. 2. 1. 3. 4. 2. 3. 4. 2. 2. 2. 3. 2. 4. 1. 1.\n",
      " 3. 1. 2. 1. 4. 3. 3. 2. 2. 2. 2. 1. 3. 4. 2. 1. 2. 2. 4. 1. 4. 3. 3. 2.\n",
      " 1. 3. 2. 3. 1. 4. 3. 2. 3. 2. 4. 4. 4. 2. 2. 3. 1. 4. 4. 3. 2. 4. 3. 3.\n",
      " 3. 3. 4. 1. 2. 2. 4. 4. 4. 2. 2. 4. 3. 1. 1. 3. 1. 4. 3. 2. 2. 3. 1. 2.\n",
      " 4. 3. 3. 4. 4. 2. 2. 3. 3. 2. 3. 2. 2. 3. 1. 2. 4. 1. 4. 4. 3. 2. 2. 1.\n",
      " 3. 4. 4. 3. 4. 3. 2. 2. 2. 3. 4. 2. 3. 1. 4. 2. 2. 3. 2. 2. 2. 2. 2. 4.\n",
      " 2. 2. 1. 2. 4. 2. 2. 1. 1. 3. 4. 2. 2. 3. 3. 2. 1. 2. 2. 2. 2. 1. 3. 3.\n",
      " 1. 4. 4. 1. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.75)\n",
    "print(f\"Y training set: {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 63)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1280      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1545 (6.04 KB)\n",
      "Trainable params: 1545 (6.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 3, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_gestures, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Path where to save the model\n",
    "model_save_path = \"model/gesture_classifier.keras\"\n",
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/7 [===>..........................] - ETA: 3s - loss: 2.0870 - accuracy: 0.2500\n",
      "Epoch 1: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 1s 37ms/step - loss: 1.9191 - accuracy: 0.2179 - val_loss: 1.4781 - val_accuracy: 0.2241\n",
      "Epoch 2/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.9263 - accuracy: 0.1875\n",
      "Epoch 2: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7614 - accuracy: 0.2179 - val_loss: 1.3835 - val_accuracy: 0.3478\n",
      "Epoch 3/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.7175 - accuracy: 0.2422\n",
      "Epoch 3: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6206 - accuracy: 0.2525 - val_loss: 1.3425 - val_accuracy: 0.4247\n",
      "Epoch 4/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.6282 - accuracy: 0.2422\n",
      "Epoch 4: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5647 - accuracy: 0.2793 - val_loss: 1.3250 - val_accuracy: 0.4649\n",
      "Epoch 5/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4014 - accuracy: 0.3203\n",
      "Epoch 5: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4717 - accuracy: 0.3318 - val_loss: 1.3155 - val_accuracy: 0.6589\n",
      "Epoch 6/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4369 - accuracy: 0.3359\n",
      "Epoch 6: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4475 - accuracy: 0.3508 - val_loss: 1.2947 - val_accuracy: 0.6622\n",
      "Epoch 7/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4438 - accuracy: 0.3359\n",
      "Epoch 7: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4003 - accuracy: 0.3665 - val_loss: 1.2606 - val_accuracy: 0.7258\n",
      "Epoch 8/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3505 - accuracy: 0.3906\n",
      "Epoch 8: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3679 - accuracy: 0.3922 - val_loss: 1.2140 - val_accuracy: 0.7659\n",
      "Epoch 9/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.2867 - accuracy: 0.4453\n",
      "Epoch 9: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3361 - accuracy: 0.3966 - val_loss: 1.1808 - val_accuracy: 0.7157\n",
      "Epoch 10/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3563 - accuracy: 0.4062\n",
      "Epoch 10: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3213 - accuracy: 0.4179 - val_loss: 1.1450 - val_accuracy: 0.8127\n",
      "Epoch 11/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3312 - accuracy: 0.4062\n",
      "Epoch 11: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2960 - accuracy: 0.4413 - val_loss: 1.1009 - val_accuracy: 0.9164\n",
      "Epoch 12/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1763 - accuracy: 0.5312\n",
      "Epoch 12: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2528 - accuracy: 0.4715 - val_loss: 1.0460 - val_accuracy: 0.9565\n",
      "Epoch 13/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1894 - accuracy: 0.4922\n",
      "Epoch 13: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2033 - accuracy: 0.5017 - val_loss: 0.9918 - val_accuracy: 0.9732\n",
      "Epoch 14/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.2659 - accuracy: 0.4844\n",
      "Epoch 14: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1885 - accuracy: 0.5151 - val_loss: 0.9413 - val_accuracy: 0.9799\n",
      "Epoch 15/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.2588 - accuracy: 0.4609\n",
      "Epoch 15: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1687 - accuracy: 0.5117 - val_loss: 0.9066 - val_accuracy: 0.9799\n",
      "Epoch 16/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1627 - accuracy: 0.5391\n",
      "Epoch 16: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0996 - accuracy: 0.5609 - val_loss: 0.8576 - val_accuracy: 0.9666\n",
      "Epoch 17/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1518 - accuracy: 0.5156\n",
      "Epoch 17: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0957 - accuracy: 0.5475 - val_loss: 0.8059 - val_accuracy: 0.9699\n",
      "Epoch 18/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0254 - accuracy: 0.6016\n",
      "Epoch 18: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0540 - accuracy: 0.5721 - val_loss: 0.7619 - val_accuracy: 0.9666\n",
      "Epoch 19/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0366 - accuracy: 0.6172\n",
      "Epoch 19: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0332 - accuracy: 0.5899 - val_loss: 0.7270 - val_accuracy: 0.9666\n",
      "Epoch 20/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1270 - accuracy: 0.4609\n",
      "Epoch 20: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0094 - accuracy: 0.5743 - val_loss: 0.6990 - val_accuracy: 0.9666\n",
      "Epoch 21/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0789 - accuracy: 0.5547\n",
      "Epoch 21: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9911 - accuracy: 0.5944 - val_loss: 0.6718 - val_accuracy: 0.9666\n",
      "Epoch 22/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9338 - accuracy: 0.6641\n",
      "Epoch 22: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9658 - accuracy: 0.6101 - val_loss: 0.6323 - val_accuracy: 0.9666\n",
      "Epoch 23/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0231 - accuracy: 0.5859\n",
      "Epoch 23: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9524 - accuracy: 0.6101 - val_loss: 0.6001 - val_accuracy: 0.9666\n",
      "Epoch 24/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9474 - accuracy: 0.6016\n",
      "Epoch 24: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9040 - accuracy: 0.6346 - val_loss: 0.5667 - val_accuracy: 0.9666\n",
      "Epoch 25/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9210 - accuracy: 0.6406\n",
      "Epoch 25: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8838 - accuracy: 0.6503 - val_loss: 0.5337 - val_accuracy: 0.9666\n",
      "Epoch 26/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8528 - accuracy: 0.6328\n",
      "Epoch 26: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8220 - accuracy: 0.6894 - val_loss: 0.5043 - val_accuracy: 0.9666\n",
      "Epoch 27/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8574 - accuracy: 0.6797\n",
      "Epoch 27: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8493 - accuracy: 0.6648 - val_loss: 0.4732 - val_accuracy: 0.9666\n",
      "Epoch 28/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7762 - accuracy: 0.7344\n",
      "Epoch 28: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8071 - accuracy: 0.6939 - val_loss: 0.4438 - val_accuracy: 0.9666\n",
      "Epoch 29/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7891 - accuracy: 0.7109\n",
      "Epoch 29: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8090 - accuracy: 0.6827 - val_loss: 0.4266 - val_accuracy: 0.9666\n",
      "Epoch 30/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6706 - accuracy: 0.7500\n",
      "Epoch 30: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7859 - accuracy: 0.6883 - val_loss: 0.4077 - val_accuracy: 0.9732\n",
      "Epoch 31/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7276 - accuracy: 0.7500\n",
      "Epoch 31: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7579 - accuracy: 0.7117 - val_loss: 0.3909 - val_accuracy: 0.9766\n",
      "Epoch 32/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8033 - accuracy: 0.6641\n",
      "Epoch 32: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7429 - accuracy: 0.7251 - val_loss: 0.3700 - val_accuracy: 0.9766\n",
      "Epoch 33/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7696 - accuracy: 0.7344\n",
      "Epoch 33: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7489 - accuracy: 0.7151 - val_loss: 0.3533 - val_accuracy: 0.9699\n",
      "Epoch 34/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6991 - accuracy: 0.7734\n",
      "Epoch 34: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7094 - accuracy: 0.7341 - val_loss: 0.3379 - val_accuracy: 0.9766\n",
      "Epoch 35/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8150 - accuracy: 0.6484\n",
      "Epoch 35: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7061 - accuracy: 0.7240 - val_loss: 0.3239 - val_accuracy: 0.9766\n",
      "Epoch 36/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7803 - accuracy: 0.6875\n",
      "Epoch 36: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7216 - accuracy: 0.7061 - val_loss: 0.3091 - val_accuracy: 0.9766\n",
      "Epoch 37/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6599 - accuracy: 0.7500\n",
      "Epoch 37: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6712 - accuracy: 0.7453 - val_loss: 0.2952 - val_accuracy: 0.9866\n",
      "Epoch 38/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6476 - accuracy: 0.7812\n",
      "Epoch 38: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6528 - accuracy: 0.7598 - val_loss: 0.2793 - val_accuracy: 0.9833\n",
      "Epoch 39/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7101 - accuracy: 0.7109\n",
      "Epoch 39: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6380 - accuracy: 0.7531 - val_loss: 0.2713 - val_accuracy: 0.9766\n",
      "Epoch 40/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5946 - accuracy: 0.7734\n",
      "Epoch 40: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6119 - accuracy: 0.7654 - val_loss: 0.2605 - val_accuracy: 0.9766\n",
      "Epoch 41/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6813 - accuracy: 0.7422\n",
      "Epoch 41: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6372 - accuracy: 0.7642 - val_loss: 0.2489 - val_accuracy: 0.9866\n",
      "Epoch 42/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5251 - accuracy: 0.8359\n",
      "Epoch 42: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5995 - accuracy: 0.7709 - val_loss: 0.2378 - val_accuracy: 0.9866\n",
      "Epoch 43/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6704 - accuracy: 0.7266\n",
      "Epoch 43: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.7575 - val_loss: 0.2298 - val_accuracy: 0.9799\n",
      "Epoch 44/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5792 - accuracy: 0.7969\n",
      "Epoch 44: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5888 - accuracy: 0.7799 - val_loss: 0.2255 - val_accuracy: 0.9833\n",
      "Epoch 45/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6019 - accuracy: 0.7266\n",
      "Epoch 45: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5992 - accuracy: 0.7464 - val_loss: 0.2178 - val_accuracy: 0.9866\n",
      "Epoch 46/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5301 - accuracy: 0.8125\n",
      "Epoch 46: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5576 - accuracy: 0.7933 - val_loss: 0.2054 - val_accuracy: 0.9866\n",
      "Epoch 47/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6739 - accuracy: 0.7266\n",
      "Epoch 47: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5876 - accuracy: 0.7564 - val_loss: 0.1992 - val_accuracy: 0.9866\n",
      "Epoch 48/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4984 - accuracy: 0.7891\n",
      "Epoch 48: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5509 - accuracy: 0.8000 - val_loss: 0.1913 - val_accuracy: 0.9866\n",
      "Epoch 49/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6651 - accuracy: 0.7188\n",
      "Epoch 49: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5718 - accuracy: 0.7844 - val_loss: 0.1851 - val_accuracy: 0.9866\n",
      "Epoch 50/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4615 - accuracy: 0.8438\n",
      "Epoch 50: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.7955 - val_loss: 0.1835 - val_accuracy: 0.9799\n",
      "Epoch 51/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4584 - accuracy: 0.8750\n",
      "Epoch 51: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.8011 - val_loss: 0.1776 - val_accuracy: 0.9866\n",
      "Epoch 52/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6645 - accuracy: 0.7578\n",
      "Epoch 52: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5504 - accuracy: 0.8112 - val_loss: 0.1773 - val_accuracy: 0.9866\n",
      "Epoch 53/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4809 - accuracy: 0.8281\n",
      "Epoch 53: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.7877 - val_loss: 0.1740 - val_accuracy: 0.9866\n",
      "Epoch 54/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4739 - accuracy: 0.8047\n",
      "Epoch 54: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5238 - accuracy: 0.7911 - val_loss: 0.1678 - val_accuracy: 0.9866\n",
      "Epoch 55/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6138 - accuracy: 0.7734\n",
      "Epoch 55: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5526 - accuracy: 0.7933 - val_loss: 0.1641 - val_accuracy: 0.9799\n",
      "Epoch 56/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4580 - accuracy: 0.8672\n",
      "Epoch 56: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.8425 - val_loss: 0.1551 - val_accuracy: 0.9799\n",
      "Epoch 57/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5226 - accuracy: 0.7891\n",
      "Epoch 57: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5107 - accuracy: 0.7911 - val_loss: 0.1505 - val_accuracy: 0.9799\n",
      "Epoch 58/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4725 - accuracy: 0.8672\n",
      "Epoch 58: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5009 - accuracy: 0.8324 - val_loss: 0.1453 - val_accuracy: 0.9732\n",
      "Epoch 59/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4510 - accuracy: 0.8359\n",
      "Epoch 59: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4638 - accuracy: 0.8358 - val_loss: 0.1391 - val_accuracy: 0.9799\n",
      "Epoch 60/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4679 - accuracy: 0.8281\n",
      "Epoch 60: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4883 - accuracy: 0.8168 - val_loss: 0.1353 - val_accuracy: 0.9866\n",
      "Epoch 61/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4468 - accuracy: 0.8359\n",
      "Epoch 61: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.8536 - val_loss: 0.1305 - val_accuracy: 0.9866\n",
      "Epoch 62/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4899 - accuracy: 0.7969\n",
      "Epoch 62: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.8257 - val_loss: 0.1287 - val_accuracy: 0.9866\n",
      "Epoch 63/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4775 - accuracy: 0.8203\n",
      "Epoch 63: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4535 - accuracy: 0.8346 - val_loss: 0.1254 - val_accuracy: 0.9900\n",
      "Epoch 64/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4526 - accuracy: 0.8125\n",
      "Epoch 64: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.8279 - val_loss: 0.1229 - val_accuracy: 0.9866\n",
      "Epoch 65/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5324 - accuracy: 0.7812\n",
      "Epoch 65: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4487 - accuracy: 0.8313 - val_loss: 0.1205 - val_accuracy: 0.9866\n",
      "Epoch 66/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3884 - accuracy: 0.8203\n",
      "Epoch 66: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8447 - val_loss: 0.1160 - val_accuracy: 0.9866\n",
      "Epoch 67/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4367 - accuracy: 0.8203\n",
      "Epoch 67: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8380 - val_loss: 0.1151 - val_accuracy: 0.9900\n",
      "Epoch 68/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3426 - accuracy: 0.8594\n",
      "Epoch 68: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8581 - val_loss: 0.1118 - val_accuracy: 0.9900\n",
      "Epoch 69/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4899 - accuracy: 0.8281\n",
      "Epoch 69: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8358 - val_loss: 0.1092 - val_accuracy: 0.9900\n",
      "Epoch 70/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4485 - accuracy: 0.8359\n",
      "Epoch 70: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3994 - accuracy: 0.8525 - val_loss: 0.1098 - val_accuracy: 0.9866\n",
      "Epoch 71/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4645 - accuracy: 0.8281\n",
      "Epoch 71: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.8302 - val_loss: 0.1078 - val_accuracy: 0.9900\n",
      "Epoch 72/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4856 - accuracy: 0.8203\n",
      "Epoch 72: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4270 - accuracy: 0.8469 - val_loss: 0.1070 - val_accuracy: 0.9900\n",
      "Epoch 73/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3760 - accuracy: 0.8594\n",
      "Epoch 73: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3775 - accuracy: 0.8615 - val_loss: 0.1049 - val_accuracy: 0.9900\n",
      "Epoch 74/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5148 - accuracy: 0.8203\n",
      "Epoch 74: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4375 - accuracy: 0.8469 - val_loss: 0.1037 - val_accuracy: 0.9900\n",
      "Epoch 75/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4489 - accuracy: 0.8438\n",
      "Epoch 75: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8514 - val_loss: 0.1016 - val_accuracy: 0.9900\n",
      "Epoch 76/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4632 - accuracy: 0.8359\n",
      "Epoch 76: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8402 - val_loss: 0.1019 - val_accuracy: 0.9900\n",
      "Epoch 77/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3504 - accuracy: 0.8516\n",
      "Epoch 77: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3923 - accuracy: 0.8715 - val_loss: 0.1004 - val_accuracy: 0.9866\n",
      "Epoch 78/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8906\n",
      "Epoch 78: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3759 - accuracy: 0.8559 - val_loss: 0.0976 - val_accuracy: 0.9866\n",
      "Epoch 79/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3827 - accuracy: 0.8750\n",
      "Epoch 79: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3786 - accuracy: 0.8670 - val_loss: 0.0965 - val_accuracy: 0.9900\n",
      "Epoch 80/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4712 - accuracy: 0.7891\n",
      "Epoch 80: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3877 - accuracy: 0.8547 - val_loss: 0.0955 - val_accuracy: 0.9866\n",
      "Epoch 81/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3703 - accuracy: 0.8984\n",
      "Epoch 81: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3664 - accuracy: 0.8872 - val_loss: 0.0900 - val_accuracy: 0.9900\n",
      "Epoch 82/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3754 - accuracy: 0.8828\n",
      "Epoch 82: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3686 - accuracy: 0.8648 - val_loss: 0.0894 - val_accuracy: 0.9866\n",
      "Epoch 83/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3382 - accuracy: 0.8906\n",
      "Epoch 83: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8659 - val_loss: 0.0922 - val_accuracy: 0.9900\n",
      "Epoch 84/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4001 - accuracy: 0.8672\n",
      "Epoch 84: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8514 - val_loss: 0.0936 - val_accuracy: 0.9900\n",
      "Epoch 85/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8828\n",
      "Epoch 85: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8804 - val_loss: 0.0922 - val_accuracy: 0.9900\n",
      "Epoch 86/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3314 - accuracy: 0.8984\n",
      "Epoch 86: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8983 - val_loss: 0.0925 - val_accuracy: 0.9900\n",
      "Epoch 87/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3070 - accuracy: 0.9141\n",
      "Epoch 87: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3712 - accuracy: 0.8771 - val_loss: 0.0926 - val_accuracy: 0.9900\n",
      "Epoch 88/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8516\n",
      "Epoch 88: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8536 - val_loss: 0.0920 - val_accuracy: 0.9866\n",
      "Epoch 89/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3632 - accuracy: 0.8438\n",
      "Epoch 89: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3832 - accuracy: 0.8603 - val_loss: 0.0916 - val_accuracy: 0.9866\n",
      "Epoch 90/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3105 - accuracy: 0.8906\n",
      "Epoch 90: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3403 - accuracy: 0.8849 - val_loss: 0.0899 - val_accuracy: 0.9799\n",
      "Epoch 91/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3546 - accuracy: 0.8594\n",
      "Epoch 91: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8749 - val_loss: 0.0878 - val_accuracy: 0.9766\n",
      "Epoch 92/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2979 - accuracy: 0.9375\n",
      "Epoch 92: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.8939 - val_loss: 0.0838 - val_accuracy: 0.9799\n",
      "Epoch 93/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3824 - accuracy: 0.8281\n",
      "Epoch 93: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.8592 - val_loss: 0.0827 - val_accuracy: 0.9799\n",
      "Epoch 94/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4440 - accuracy: 0.8203\n",
      "Epoch 94: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.8670 - val_loss: 0.0836 - val_accuracy: 0.9766\n",
      "Epoch 95/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3552 - accuracy: 0.8828\n",
      "Epoch 95: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.8972 - val_loss: 0.0821 - val_accuracy: 0.9766\n",
      "Epoch 96/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4313 - accuracy: 0.8594\n",
      "Epoch 96: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3538 - accuracy: 0.8648 - val_loss: 0.0826 - val_accuracy: 0.9799\n",
      "Epoch 97/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4047 - accuracy: 0.8516\n",
      "Epoch 97: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8804 - val_loss: 0.0817 - val_accuracy: 0.9799\n",
      "Epoch 98/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3857 - accuracy: 0.8984\n",
      "Epoch 98: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.9017 - val_loss: 0.0796 - val_accuracy: 0.9866\n",
      "Epoch 99/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2877 - accuracy: 0.8984\n",
      "Epoch 99: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8737 - val_loss: 0.0777 - val_accuracy: 0.9900\n",
      "Epoch 100/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3342 - accuracy: 0.8828\n",
      "Epoch 100: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.8782 - val_loss: 0.0781 - val_accuracy: 0.9866\n",
      "Epoch 101/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8906\n",
      "Epoch 101: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3325 - accuracy: 0.8804 - val_loss: 0.0799 - val_accuracy: 0.9833\n",
      "Epoch 102/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3117 - accuracy: 0.8828\n",
      "Epoch 102: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.8838 - val_loss: 0.0803 - val_accuracy: 0.9833\n",
      "Epoch 103/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3380 - accuracy: 0.9141\n",
      "Epoch 103: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3556 - accuracy: 0.8771 - val_loss: 0.0807 - val_accuracy: 0.9866\n",
      "Epoch 104/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3360 - accuracy: 0.8594\n",
      "Epoch 104: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.8771 - val_loss: 0.0800 - val_accuracy: 0.9833\n",
      "Epoch 105/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2505 - accuracy: 0.9297\n",
      "Epoch 105: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2976 - accuracy: 0.8972 - val_loss: 0.0767 - val_accuracy: 0.9833\n",
      "Epoch 106/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3437 - accuracy: 0.8828\n",
      "Epoch 106: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3194 - accuracy: 0.8883 - val_loss: 0.0743 - val_accuracy: 0.9900\n",
      "Epoch 107/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8516\n",
      "Epoch 107: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3109 - accuracy: 0.8793 - val_loss: 0.0739 - val_accuracy: 0.9866\n",
      "Epoch 108/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8750\n",
      "Epoch 108: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8771 - val_loss: 0.0739 - val_accuracy: 0.9866\n",
      "Epoch 109/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2991 - accuracy: 0.8984\n",
      "Epoch 109: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3275 - accuracy: 0.8782 - val_loss: 0.0745 - val_accuracy: 0.9833\n",
      "Epoch 110/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2797 - accuracy: 0.8984\n",
      "Epoch 110: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2940 - accuracy: 0.9017 - val_loss: 0.0765 - val_accuracy: 0.9833\n",
      "Epoch 111/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2949 - accuracy: 0.8828\n",
      "Epoch 111: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3170 - accuracy: 0.8816 - val_loss: 0.0764 - val_accuracy: 0.9900\n",
      "Epoch 112/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2897 - accuracy: 0.8984\n",
      "Epoch 112: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3100 - accuracy: 0.8894 - val_loss: 0.0747 - val_accuracy: 0.9900\n",
      "Epoch 113/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3568 - accuracy: 0.8438\n",
      "Epoch 113: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3199 - accuracy: 0.8883 - val_loss: 0.0723 - val_accuracy: 0.9900\n",
      "Epoch 114/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3391 - accuracy: 0.8672\n",
      "Epoch 114: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2920 - accuracy: 0.8972 - val_loss: 0.0739 - val_accuracy: 0.9799\n",
      "Epoch 115/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2803 - accuracy: 0.8594\n",
      "Epoch 115: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3141 - accuracy: 0.8849 - val_loss: 0.0740 - val_accuracy: 0.9766\n",
      "Epoch 116/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8984\n",
      "Epoch 116: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.8670 - val_loss: 0.0730 - val_accuracy: 0.9732\n",
      "Epoch 117/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2670 - accuracy: 0.9297\n",
      "Epoch 117: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.8816 - val_loss: 0.0738 - val_accuracy: 0.9766\n",
      "Epoch 118/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2225 - accuracy: 0.9453\n",
      "Epoch 118: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.8939 - val_loss: 0.0749 - val_accuracy: 0.9766\n",
      "Epoch 119/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8828\n",
      "Epoch 119: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3113 - accuracy: 0.8872 - val_loss: 0.0745 - val_accuracy: 0.9866\n",
      "Epoch 120/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2794 - accuracy: 0.9062\n",
      "Epoch 120: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2950 - accuracy: 0.8927 - val_loss: 0.0742 - val_accuracy: 0.9900\n",
      "Epoch 121/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8906\n",
      "Epoch 121: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3199 - accuracy: 0.8872 - val_loss: 0.0751 - val_accuracy: 0.9866\n",
      "Epoch 122/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8906\n",
      "Epoch 122: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2761 - accuracy: 0.9050 - val_loss: 0.0747 - val_accuracy: 0.9833\n",
      "Epoch 123/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8828\n",
      "Epoch 123: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8894 - val_loss: 0.0742 - val_accuracy: 0.9833\n",
      "Epoch 124/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3105 - accuracy: 0.8594\n",
      "Epoch 124: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3139 - accuracy: 0.8804 - val_loss: 0.0751 - val_accuracy: 0.9766\n",
      "Epoch 125/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9297\n",
      "Epoch 125: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8849 - val_loss: 0.0754 - val_accuracy: 0.9732\n",
      "Epoch 126/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2367 - accuracy: 0.9219\n",
      "Epoch 126: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3015 - accuracy: 0.8883 - val_loss: 0.0743 - val_accuracy: 0.9732\n",
      "Epoch 127/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2886 - accuracy: 0.8828\n",
      "Epoch 127: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3005 - accuracy: 0.8983 - val_loss: 0.0711 - val_accuracy: 0.9732\n",
      "Epoch 128/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2682 - accuracy: 0.9219\n",
      "Epoch 128: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2659 - accuracy: 0.9095 - val_loss: 0.0685 - val_accuracy: 0.9766\n",
      "Epoch 129/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2973 - accuracy: 0.8984\n",
      "Epoch 129: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3002 - accuracy: 0.9006 - val_loss: 0.0682 - val_accuracy: 0.9833\n",
      "Epoch 130/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3714 - accuracy: 0.8906\n",
      "Epoch 130: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3119 - accuracy: 0.8905 - val_loss: 0.0705 - val_accuracy: 0.9833\n",
      "Epoch 131/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2903 - accuracy: 0.9141\n",
      "Epoch 131: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2655 - accuracy: 0.9073 - val_loss: 0.0703 - val_accuracy: 0.9866\n",
      "Epoch 132/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3050 - accuracy: 0.8984\n",
      "Epoch 132: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2586 - accuracy: 0.9106 - val_loss: 0.0688 - val_accuracy: 0.9766\n",
      "Epoch 133/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2894 - accuracy: 0.9141\n",
      "Epoch 133: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2787 - accuracy: 0.9028 - val_loss: 0.0664 - val_accuracy: 0.9766\n",
      "Epoch 134/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8906\n",
      "Epoch 134: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 0.8939 - val_loss: 0.0653 - val_accuracy: 0.9799\n",
      "Epoch 135/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2768 - accuracy: 0.8828\n",
      "Epoch 135: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2662 - accuracy: 0.9028 - val_loss: 0.0670 - val_accuracy: 0.9766\n",
      "Epoch 136/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2423 - accuracy: 0.9375\n",
      "Epoch 136: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2812 - accuracy: 0.9017 - val_loss: 0.0661 - val_accuracy: 0.9766\n",
      "Epoch 137/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2334 - accuracy: 0.9375\n",
      "Epoch 137: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2592 - accuracy: 0.9128 - val_loss: 0.0670 - val_accuracy: 0.9766\n",
      "Epoch 138/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9219\n",
      "Epoch 138: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2757 - accuracy: 0.8972 - val_loss: 0.0676 - val_accuracy: 0.9732\n",
      "Epoch 139/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8516\n",
      "Epoch 139: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2837 - accuracy: 0.8838 - val_loss: 0.0679 - val_accuracy: 0.9766\n",
      "Epoch 140/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2512 - accuracy: 0.8906\n",
      "Epoch 140: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2616 - accuracy: 0.9095 - val_loss: 0.0674 - val_accuracy: 0.9766\n",
      "Epoch 141/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2535 - accuracy: 0.9375\n",
      "Epoch 141: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2791 - accuracy: 0.8994 - val_loss: 0.0657 - val_accuracy: 0.9766\n",
      "Epoch 142/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2834 - accuracy: 0.8984\n",
      "Epoch 142: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2866 - accuracy: 0.8927 - val_loss: 0.0656 - val_accuracy: 0.9900\n",
      "Epoch 143/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8750\n",
      "Epoch 143: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2981 - accuracy: 0.8950 - val_loss: 0.0690 - val_accuracy: 0.9866\n",
      "Epoch 144/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2727 - accuracy: 0.9219\n",
      "Epoch 144: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2675 - accuracy: 0.9050 - val_loss: 0.0701 - val_accuracy: 0.9799\n",
      "Epoch 145/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8516\n",
      "Epoch 145: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8827 - val_loss: 0.0684 - val_accuracy: 0.9766\n",
      "Epoch 146/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2070 - accuracy: 0.9219\n",
      "Epoch 146: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2563 - accuracy: 0.9039 - val_loss: 0.0663 - val_accuracy: 0.9799\n",
      "Epoch 147/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9531\n",
      "Epoch 147: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2610 - accuracy: 0.9095 - val_loss: 0.0638 - val_accuracy: 0.9833\n",
      "Epoch 148/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2615 - accuracy: 0.8984\n",
      "Epoch 148: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2615 - accuracy: 0.9117 - val_loss: 0.0644 - val_accuracy: 0.9766\n",
      "Epoch 149/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2581 - accuracy: 0.8828\n",
      "Epoch 149: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2699 - accuracy: 0.8883 - val_loss: 0.0645 - val_accuracy: 0.9766\n",
      "Epoch 150/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2101 - accuracy: 0.9219\n",
      "Epoch 150: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2545 - accuracy: 0.9184 - val_loss: 0.0649 - val_accuracy: 0.9833\n",
      "Epoch 151/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2225 - accuracy: 0.9453\n",
      "Epoch 151: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2902 - accuracy: 0.9017 - val_loss: 0.0654 - val_accuracy: 0.9866\n",
      "Epoch 152/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2581 - accuracy: 0.8906\n",
      "Epoch 152: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2407 - accuracy: 0.9140 - val_loss: 0.0672 - val_accuracy: 0.9766\n",
      "Epoch 153/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3442 - accuracy: 0.8672\n",
      "Epoch 153: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3067 - accuracy: 0.8894 - val_loss: 0.0660 - val_accuracy: 0.9799\n",
      "Epoch 154/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8516\n",
      "Epoch 154: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9050 - val_loss: 0.0692 - val_accuracy: 0.9766\n",
      "Epoch 155/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2948 - accuracy: 0.8672\n",
      "Epoch 155: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2875 - accuracy: 0.8972 - val_loss: 0.0728 - val_accuracy: 0.9799\n",
      "Epoch 156/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4271 - accuracy: 0.8203\n",
      "Epoch 156: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2833 - accuracy: 0.8883 - val_loss: 0.0704 - val_accuracy: 0.9766\n",
      "Epoch 157/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3146 - accuracy: 0.9062\n",
      "Epoch 157: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2631 - accuracy: 0.9061 - val_loss: 0.0683 - val_accuracy: 0.9799\n",
      "Epoch 158/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2747 - accuracy: 0.8828\n",
      "Epoch 158: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2647 - accuracy: 0.8983 - val_loss: 0.0690 - val_accuracy: 0.9799\n",
      "Epoch 159/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2589 - accuracy: 0.8984\n",
      "Epoch 159: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2833 - accuracy: 0.8994 - val_loss: 0.0695 - val_accuracy: 0.9799\n",
      "Epoch 160/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2990 - accuracy: 0.9219\n",
      "Epoch 160: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2431 - accuracy: 0.9173 - val_loss: 0.0694 - val_accuracy: 0.9833\n",
      "Epoch 161/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3810 - accuracy: 0.8594\n",
      "Epoch 161: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2975 - accuracy: 0.8927 - val_loss: 0.0678 - val_accuracy: 0.9833\n",
      "Epoch 162/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2744 - accuracy: 0.9062\n",
      "Epoch 162: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2348 - accuracy: 0.9229 - val_loss: 0.0664 - val_accuracy: 0.9833\n",
      "Epoch 163/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3308 - accuracy: 0.8828\n",
      "Epoch 163: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2552 - accuracy: 0.9084 - val_loss: 0.0660 - val_accuracy: 0.9799\n",
      "Epoch 164/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2725 - accuracy: 0.9219\n",
      "Epoch 164: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.9196 - val_loss: 0.0665 - val_accuracy: 0.9766\n",
      "Epoch 165/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2269 - accuracy: 0.9062\n",
      "Epoch 165: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2670 - accuracy: 0.9017 - val_loss: 0.0691 - val_accuracy: 0.9766\n",
      "Epoch 166/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2615 - accuracy: 0.8906\n",
      "Epoch 166: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2638 - accuracy: 0.9017 - val_loss: 0.0690 - val_accuracy: 0.9766\n",
      "Epoch 167/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2488 - accuracy: 0.9297\n",
      "Epoch 167: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2703 - accuracy: 0.9039 - val_loss: 0.0678 - val_accuracy: 0.9799\n",
      "Epoch 167: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f705c457a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model with inference optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 823us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        60\n",
      "         2.0       0.97      1.00      0.99       105\n",
      "         3.0       0.95      0.95      0.95        66\n",
      "         4.0       1.00      0.96      0.98        68\n",
      "\n",
      "    accuracy                           0.98       299\n",
      "   macro avg       0.98      0.98      0.98       299\n",
      "weighted avg       0.98      0.98      0.98       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "[6.8494282e-06 5.4038019e-04 1.0184651e-03 9.6280247e-01 3.5631865e-02]\n",
      "3\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "i = 678\n",
    "predict_result = model.predict(np.array([x_data[i]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "print(y_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tflite model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj9jxblro/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpj9jxblro/assets\n",
      "2024-10-24 16:47:18.205573: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-10-24 16:47:18.205601: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-10-24 16:47:18.206177: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpj9jxblro\n",
      "2024-10-24 16:47:18.207191: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-10-24 16:47:18.207206: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmpj9jxblro\n",
      "2024-10-24 16:47:18.210164: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2024-10-24 16:47:18.211016: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-10-24 16:47:18.247670: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpj9jxblro\n",
      "2024-10-24 16:47:18.259316: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 53141 microseconds.\n",
      "2024-10-24 16:47:18.291514: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4592"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_save_path = \"model/gesture_classifier.tflite\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8372583e-06 9.8225337e-01 1.5259739e-02 1.3874361e-04 2.3452772e-03]\n",
      "1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "i = 452\n",
    "interpreter.set_tensor(input_details[0]['index'], np.array([x_data[i]]))\n",
    "\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))\n",
    "print(y_data[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
