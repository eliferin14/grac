{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model training for gesture recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 19:25:34.720789: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-23 19:25:34.766256: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-23 19:25:34.766981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 19:25:35.705207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the list of gesture form the `gesture_list.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none' 'open' 'fist' 'index' 'L']\n"
     ]
    }
   ],
   "source": [
    "# Define which gestures should be detected by the model\n",
    "gesture_list = np.loadtxt(\"gesture_list.csv\", delimiter=',', dtype=str)\n",
    "print(gesture_list)\n",
    "num_gestures = len(gesture_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_filepath = \"dataset.csv\"\n",
    "handedness = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.str_, usecols=(0))\n",
    "y_data_labels = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.str_, usecols=(1))\n",
    "x_data = np.loadtxt(dataset_filepath, delimiter=',', dtype=np.float32, usecols=list(range(2, (21*3)+2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left\n",
      "open\n",
      "(1194, 63)\n",
      "(63,)\n"
     ]
    }
   ],
   "source": [
    "print(handedness[0])\n",
    "print(y_data_labels[0])\n",
    "print(x_data.shape)\n",
    "print(x_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 300\n",
      "fist: 394\n",
      "index: 300\n",
      "open: 200\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_data_labels, return_counts=True)\n",
    "label_count = dict(zip(unique, counts))\n",
    "for elem in label_count:\n",
    "    print(f\"{elem}: {label_count[elem]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data: convert to N x 21 x 3 -> normalization -> convert to N x 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = x_data.shape[0]\n",
    "x_data_tensor = np.zeros((N,21,3))\n",
    "for i in range(N):\n",
    "    for j in range(21):\n",
    "        for k in range(3):\n",
    "            x_data_tensor[i,j,k] = x_data[i, 3*j+k]\n",
    "\n",
    "assert x_data[200,15] == x_data_tensor[200, 5, 0]\n",
    "\n",
    "from landmark_normalizer import HandLandmarkNormalizer\n",
    "hln = HandLandmarkNormalizer()\n",
    "    \n",
    "x_data_normalized = np.zeros_like(x_data)\n",
    "for i, gesture in enumerate(x_data_tensor):\n",
    "    x_data_normalized[i] = hln(gesture, handedness[i]).reshape(-1)\n",
    "    \n",
    "assert x_data_normalized.shape == x_data.shape\n",
    "\n",
    "x_data = x_data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the ID of each gesture. The ID coincides with the row number in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.zeros((y_data_labels.shape[0]))\n",
    "for i, label in enumerate(y_data_labels):\n",
    "    for j, gesture in enumerate(gesture_list):\n",
    "        if label == gesture and gesture in gesture_list:\n",
    "            # \"Substitute\" the label with the gesture id\n",
    "            y_data[i] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y training set: [4. 2. 2. 4. 4. 4. 4. 2. 3. 4. 4. 4. 4. 4. 4. 1. 3. 4. 2. 1. 3. 1. 1. 4.\n",
      " 2. 4. 4. 3. 4. 3. 1. 2. 3. 1. 2. 2. 2. 3. 2. 4. 3. 3. 4. 2. 2. 2. 4. 1.\n",
      " 4. 4. 3. 4. 1. 3. 2. 3. 2. 2. 3. 3. 3. 4. 1. 2. 2. 4. 4. 3. 3. 4. 4. 3.\n",
      " 4. 4. 4. 3. 2. 3. 1. 2. 3. 3. 1. 1. 4. 2. 3. 1. 4. 2. 4. 2. 4. 4. 3. 2.\n",
      " 4. 4. 2. 3. 4. 1. 3. 4. 2. 1. 2. 3. 2. 2. 3. 2. 1. 2. 3. 2. 4. 1. 4. 2.\n",
      " 4. 2. 4. 2. 2. 2. 2. 2. 3. 2. 3. 4. 2. 4. 2. 2. 2. 3. 3. 2. 1. 2. 4. 1.\n",
      " 4. 4. 4. 3. 1. 3. 2. 4. 3. 2. 4. 3. 2. 4. 2. 2. 3. 1. 3. 2. 3. 1. 3. 2.\n",
      " 2. 3. 4. 1. 4. 3. 4. 4. 2. 2. 4. 4. 3. 1. 1. 4. 3. 4. 4. 3. 2. 2. 3. 3.\n",
      " 2. 2. 3. 3. 4. 2. 4. 2. 1. 4. 1. 4. 4. 2. 1. 1. 3. 1. 4. 1. 2. 1. 3. 2.\n",
      " 2. 4. 2. 4. 4. 2. 4. 2. 3. 3. 4. 1. 2. 1. 4. 1. 2. 4. 3. 3. 2. 3. 3. 1.\n",
      " 4. 4. 2. 3. 2. 1. 2. 4. 2. 2. 2. 1. 1. 1. 3. 1. 3. 4. 2. 2. 4. 2. 4. 4.\n",
      " 3. 3. 2. 3. 3. 2. 4. 4. 4. 2. 1. 4. 3. 2. 2. 1. 3. 1. 2. 3. 2. 2. 2. 2.\n",
      " 4. 3. 3. 3. 2. 1. 2. 2. 3. 1. 3. 4. 1. 4. 2. 4. 1. 2. 3. 3. 4. 4. 1. 2.\n",
      " 3. 3. 3. 4. 4. 4. 3. 2. 1. 1. 2. 1. 3. 4. 3. 3. 1. 2. 1. 3. 2. 4. 1. 1.\n",
      " 4. 4. 3. 4. 2. 3. 4. 2. 4. 4. 2. 2. 2. 2. 2. 3. 1. 2. 3. 4. 2. 3. 1. 4.\n",
      " 3. 1. 1. 1. 3. 2. 3. 2. 4. 3. 2. 2. 3. 2. 1. 4. 2. 4. 2. 4. 3. 2. 3. 1.\n",
      " 3. 4. 1. 2. 3. 3. 2. 2. 3. 3. 2. 3. 4. 3. 4. 4. 2. 2. 1. 4. 3. 1. 2. 1.\n",
      " 2. 1. 2. 3. 4. 4. 2. 4. 4. 2. 4. 2. 4. 2. 2. 3. 3. 1. 3. 2. 3. 1. 2. 2.\n",
      " 4. 3. 3. 3. 1. 3. 4. 1. 2. 4. 2. 2. 4. 4. 3. 2. 3. 2. 1. 3. 2. 4. 4. 2.\n",
      " 2. 2. 3. 2. 1. 2. 1. 2. 4. 3. 2. 4. 3. 2. 3. 1. 2. 2. 2. 1. 2. 4. 4. 2.\n",
      " 2. 4. 4. 1. 3. 3. 4. 2. 3. 2. 2. 3. 4. 1. 4. 4. 4. 3. 2. 4. 1. 2. 2. 1.\n",
      " 2. 4. 1. 4. 2. 4. 3. 3. 4. 4. 2. 4. 4. 2. 2. 2. 3. 3. 2. 2. 2. 4. 3. 3.\n",
      " 4. 2. 3. 2. 2. 3. 2. 4. 2. 1. 1. 4. 3. 3. 4. 3. 2. 3. 3. 4. 1. 1. 1. 4.\n",
      " 4. 1. 3. 2. 4. 3. 2. 3. 4. 4. 2. 3. 3. 2. 1. 3. 4. 2. 3. 1. 2. 1. 2. 3.\n",
      " 2. 3. 3. 4. 2. 1. 2. 4. 3. 2. 3. 3. 2. 3. 4. 2. 3. 2. 2. 2. 1. 2. 2. 3.\n",
      " 1. 1. 1. 4. 3. 3. 3. 4. 2. 3. 2. 4. 1. 1. 3. 1. 1. 3. 3. 3. 4. 1. 4. 4.\n",
      " 4. 2. 2. 2. 4. 4. 2. 3. 2. 1. 2. 2. 1. 4. 1. 3. 2. 2. 3. 3. 3. 2. 1. 2.\n",
      " 4. 1. 2. 2. 2. 2. 1. 2. 4. 3. 3. 4. 2. 4. 4. 2. 2. 2. 3. 4. 2. 1. 1. 3.\n",
      " 3. 2. 3. 2. 2. 3. 1. 2. 2. 4. 4. 3. 4. 1. 2. 1. 3. 2. 2. 3. 2. 3. 2. 3.\n",
      " 3. 3. 3. 1. 1. 1. 4. 1. 2. 1. 1. 1. 3. 4. 2. 2. 2. 1. 3. 4. 2. 3. 2. 1.\n",
      " 4. 1. 2. 2. 4. 1. 2. 1. 4. 4. 2. 1. 2. 2. 3. 4. 2. 4. 2. 3. 1. 4. 4. 3.\n",
      " 1. 4. 3. 4. 1. 3. 2. 4. 4. 4. 3. 1. 2. 2. 4. 4. 1. 1. 2. 1. 3. 4. 3. 4.\n",
      " 4. 2. 3. 3. 3. 4. 2. 4. 2. 1. 3. 4. 4. 3. 1. 4. 1. 4. 2. 2. 2. 2. 3. 2.\n",
      " 1. 2. 2. 4. 2. 3. 2. 2. 1. 1. 2. 2. 1. 1. 2. 4. 2. 2. 2. 4. 4. 2. 3. 4.\n",
      " 3. 4. 3. 3. 2. 4. 1. 2. 1. 4. 2. 2. 4. 3. 1. 3. 1. 1. 1. 4. 4. 2. 4. 2.\n",
      " 1. 3. 1. 3. 3. 4. 3. 4. 2. 3. 2. 2. 2. 2. 4. 3. 2. 3. 4. 3. 3. 2. 2. 2.\n",
      " 2. 1. 4. 3. 2. 1. 2. 2. 2. 3. 2. 4. 3. 4. 3. 4. 4. 3. 3. 3. 1. 3. 3. 1.\n",
      " 4. 3. 3. 1. 2. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.75)\n",
    "print(f\"Y training set: {y_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 63)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1280      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1545 (6.04 KB)\n",
      "Trainable params: 1545 (6.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 3, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_gestures, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# Path where to save the model\n",
    "model_save_path = \"model/gesture_classifier.keras\"\n",
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/7 [===>..........................] - ETA: 3s - loss: 1.6120 - accuracy: 0.2422\n",
      "Epoch 1: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 1s 35ms/step - loss: 1.6154 - accuracy: 0.2447 - val_loss: 1.5669 - val_accuracy: 0.2742\n",
      "Epoch 2/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.6264 - accuracy: 0.2031\n",
      "Epoch 2: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.5915 - accuracy: 0.2425 - val_loss: 1.5414 - val_accuracy: 0.2676\n",
      "Epoch 3/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.5849 - accuracy: 0.2422\n",
      "Epoch 3: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5519 - accuracy: 0.2860 - val_loss: 1.5032 - val_accuracy: 0.2642\n",
      "Epoch 4/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.5274 - accuracy: 0.2969\n",
      "Epoch 4: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5029 - accuracy: 0.3318 - val_loss: 1.4491 - val_accuracy: 0.4080\n",
      "Epoch 5/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4836 - accuracy: 0.3281\n",
      "Epoch 5: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4717 - accuracy: 0.3419 - val_loss: 1.3934 - val_accuracy: 0.5084\n",
      "Epoch 6/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4995 - accuracy: 0.3203\n",
      "Epoch 6: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4332 - accuracy: 0.3721 - val_loss: 1.3423 - val_accuracy: 0.5585\n",
      "Epoch 7/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.4258 - accuracy: 0.3359\n",
      "Epoch 7: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3857 - accuracy: 0.4011 - val_loss: 1.2933 - val_accuracy: 0.6120\n",
      "Epoch 8/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3220 - accuracy: 0.4219\n",
      "Epoch 8: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3344 - accuracy: 0.4436 - val_loss: 1.2413 - val_accuracy: 0.6455\n",
      "Epoch 9/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3738 - accuracy: 0.3828\n",
      "Epoch 9: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3211 - accuracy: 0.4235 - val_loss: 1.1913 - val_accuracy: 0.6689\n",
      "Epoch 10/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.3288 - accuracy: 0.4766\n",
      "Epoch 10: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2912 - accuracy: 0.4525 - val_loss: 1.1444 - val_accuracy: 0.6823\n",
      "Epoch 11/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.2533 - accuracy: 0.4375\n",
      "Epoch 11: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2681 - accuracy: 0.4402 - val_loss: 1.1007 - val_accuracy: 0.6890\n",
      "Epoch 12/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.2237 - accuracy: 0.5312\n",
      "Epoch 12: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2251 - accuracy: 0.4726 - val_loss: 1.0616 - val_accuracy: 0.6923\n",
      "Epoch 13/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1780 - accuracy: 0.5547\n",
      "Epoch 13: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1839 - accuracy: 0.5151 - val_loss: 1.0209 - val_accuracy: 0.7191\n",
      "Epoch 14/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1250 - accuracy: 0.5781\n",
      "Epoch 14: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1699 - accuracy: 0.5196 - val_loss: 0.9793 - val_accuracy: 0.7224\n",
      "Epoch 15/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0810 - accuracy: 0.5391\n",
      "Epoch 15: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1050 - accuracy: 0.5430 - val_loss: 0.9399 - val_accuracy: 0.7258\n",
      "Epoch 16/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1121 - accuracy: 0.5469\n",
      "Epoch 16: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1234 - accuracy: 0.5274 - val_loss: 0.9036 - val_accuracy: 0.7258\n",
      "Epoch 17/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.1089 - accuracy: 0.5703\n",
      "Epoch 17: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0831 - accuracy: 0.5609 - val_loss: 0.8713 - val_accuracy: 0.7391\n",
      "Epoch 18/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0937 - accuracy: 0.5234\n",
      "Epoch 18: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0473 - accuracy: 0.5765 - val_loss: 0.8361 - val_accuracy: 0.7492\n",
      "Epoch 19/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0150 - accuracy: 0.5859\n",
      "Epoch 19: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0317 - accuracy: 0.5665 - val_loss: 0.8067 - val_accuracy: 0.7492\n",
      "Epoch 20/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 1.0779 - accuracy: 0.5469\n",
      "Epoch 20: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0139 - accuracy: 0.5765 - val_loss: 0.7717 - val_accuracy: 0.7625\n",
      "Epoch 21/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9991 - accuracy: 0.5703\n",
      "Epoch 21: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0083 - accuracy: 0.5844 - val_loss: 0.7359 - val_accuracy: 0.7993\n",
      "Epoch 22/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9111 - accuracy: 0.6797\n",
      "Epoch 22: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9655 - accuracy: 0.6168 - val_loss: 0.6986 - val_accuracy: 0.8696\n",
      "Epoch 23/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8702 - accuracy: 0.6719\n",
      "Epoch 23: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9381 - accuracy: 0.6369 - val_loss: 0.6698 - val_accuracy: 0.8796\n",
      "Epoch 24/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9393 - accuracy: 0.6172\n",
      "Epoch 24: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9083 - accuracy: 0.6458 - val_loss: 0.6439 - val_accuracy: 0.8796\n",
      "Epoch 25/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8800 - accuracy: 0.6562\n",
      "Epoch 25: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8524 - accuracy: 0.6648 - val_loss: 0.6179 - val_accuracy: 0.8729\n",
      "Epoch 26/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.9980 - accuracy: 0.5938\n",
      "Epoch 26: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9273 - accuracy: 0.6123 - val_loss: 0.5920 - val_accuracy: 0.8963\n",
      "Epoch 27/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8531 - accuracy: 0.6484\n",
      "Epoch 27: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8613 - accuracy: 0.6704 - val_loss: 0.5657 - val_accuracy: 0.9130\n",
      "Epoch 28/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8134 - accuracy: 0.6953\n",
      "Epoch 28: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8167 - accuracy: 0.6916 - val_loss: 0.5368 - val_accuracy: 0.9431\n",
      "Epoch 29/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8206 - accuracy: 0.6797\n",
      "Epoch 29: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8462 - accuracy: 0.6793 - val_loss: 0.5123 - val_accuracy: 0.9498\n",
      "Epoch 30/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7266 - accuracy: 0.6953\n",
      "Epoch 30: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7608 - accuracy: 0.6972 - val_loss: 0.4921 - val_accuracy: 0.9465\n",
      "Epoch 31/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.8226 - accuracy: 0.6797\n",
      "Epoch 31: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7515 - accuracy: 0.7218 - val_loss: 0.4658 - val_accuracy: 0.9532\n",
      "Epoch 32/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7019 - accuracy: 0.7266\n",
      "Epoch 32: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7378 - accuracy: 0.7207 - val_loss: 0.4313 - val_accuracy: 0.9732\n",
      "Epoch 33/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6861 - accuracy: 0.7734\n",
      "Epoch 33: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7457 - accuracy: 0.7229 - val_loss: 0.4084 - val_accuracy: 0.9766\n",
      "Epoch 34/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7690 - accuracy: 0.7031\n",
      "Epoch 34: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7416 - accuracy: 0.7251 - val_loss: 0.3904 - val_accuracy: 0.9766\n",
      "Epoch 35/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7317 - accuracy: 0.7266\n",
      "Epoch 35: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7013 - accuracy: 0.7430 - val_loss: 0.3796 - val_accuracy: 0.9732\n",
      "Epoch 36/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6723 - accuracy: 0.7188\n",
      "Epoch 36: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.7341 - val_loss: 0.3606 - val_accuracy: 0.9732\n",
      "Epoch 37/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6288 - accuracy: 0.7500\n",
      "Epoch 37: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6515 - accuracy: 0.7441 - val_loss: 0.3486 - val_accuracy: 0.9732\n",
      "Epoch 38/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.7477 - accuracy: 0.7031\n",
      "Epoch 38: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6768 - accuracy: 0.7430 - val_loss: 0.3466 - val_accuracy: 0.9732\n",
      "Epoch 39/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6745 - accuracy: 0.8047\n",
      "Epoch 39: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6842 - accuracy: 0.7475 - val_loss: 0.3282 - val_accuracy: 0.9732\n",
      "Epoch 40/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6051 - accuracy: 0.7812\n",
      "Epoch 40: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6558 - accuracy: 0.7642 - val_loss: 0.3140 - val_accuracy: 0.9732\n",
      "Epoch 41/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6975 - accuracy: 0.6953\n",
      "Epoch 41: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6523 - accuracy: 0.7307 - val_loss: 0.2985 - val_accuracy: 0.9732\n",
      "Epoch 42/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6143 - accuracy: 0.7891\n",
      "Epoch 42: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6336 - accuracy: 0.7575 - val_loss: 0.2813 - val_accuracy: 0.9732\n",
      "Epoch 43/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6492 - accuracy: 0.7656\n",
      "Epoch 43: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6057 - accuracy: 0.7754 - val_loss: 0.2723 - val_accuracy: 0.9732\n",
      "Epoch 44/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6200 - accuracy: 0.7812\n",
      "Epoch 44: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5976 - accuracy: 0.7844 - val_loss: 0.2712 - val_accuracy: 0.9732\n",
      "Epoch 45/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6026 - accuracy: 0.7500\n",
      "Epoch 45: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5930 - accuracy: 0.7665 - val_loss: 0.2563 - val_accuracy: 0.9732\n",
      "Epoch 46/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.6694 - accuracy: 0.7422\n",
      "Epoch 46: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5676 - accuracy: 0.7855 - val_loss: 0.2524 - val_accuracy: 0.9732\n",
      "Epoch 47/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5207 - accuracy: 0.8203\n",
      "Epoch 47: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5416 - accuracy: 0.8134 - val_loss: 0.2410 - val_accuracy: 0.9732\n",
      "Epoch 48/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5048 - accuracy: 0.8047\n",
      "Epoch 48: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5170 - accuracy: 0.8145 - val_loss: 0.2259 - val_accuracy: 0.9732\n",
      "Epoch 49/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5322 - accuracy: 0.8125\n",
      "Epoch 49: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5448 - accuracy: 0.7966 - val_loss: 0.2121 - val_accuracy: 0.9766\n",
      "Epoch 50/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5639 - accuracy: 0.8516\n",
      "Epoch 50: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5316 - accuracy: 0.8235 - val_loss: 0.2012 - val_accuracy: 0.9732\n",
      "Epoch 51/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5105 - accuracy: 0.8516\n",
      "Epoch 51: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.8235 - val_loss: 0.1933 - val_accuracy: 0.9766\n",
      "Epoch 52/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5491 - accuracy: 0.7656\n",
      "Epoch 52: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5023 - accuracy: 0.8145 - val_loss: 0.1896 - val_accuracy: 0.9766\n",
      "Epoch 53/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4968 - accuracy: 0.8203\n",
      "Epoch 53: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5040 - accuracy: 0.8078 - val_loss: 0.1869 - val_accuracy: 0.9766\n",
      "Epoch 54/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5336 - accuracy: 0.8203\n",
      "Epoch 54: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5320 - accuracy: 0.8056 - val_loss: 0.1823 - val_accuracy: 0.9732\n",
      "Epoch 55/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4118 - accuracy: 0.8594\n",
      "Epoch 55: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.8559 - val_loss: 0.1834 - val_accuracy: 0.9732\n",
      "Epoch 56/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5552 - accuracy: 0.8047\n",
      "Epoch 56: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4966 - accuracy: 0.8101 - val_loss: 0.1782 - val_accuracy: 0.9699\n",
      "Epoch 57/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5248 - accuracy: 0.7969\n",
      "Epoch 57: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5051 - accuracy: 0.8223 - val_loss: 0.1738 - val_accuracy: 0.9732\n",
      "Epoch 58/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5074 - accuracy: 0.8125\n",
      "Epoch 58: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4907 - accuracy: 0.8335 - val_loss: 0.1761 - val_accuracy: 0.9732\n",
      "Epoch 59/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4786 - accuracy: 0.7812\n",
      "Epoch 59: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4645 - accuracy: 0.8291 - val_loss: 0.1738 - val_accuracy: 0.9732\n",
      "Epoch 60/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3910 - accuracy: 0.8438\n",
      "Epoch 60: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4423 - accuracy: 0.8413 - val_loss: 0.1718 - val_accuracy: 0.9699\n",
      "Epoch 61/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8516\n",
      "Epoch 61: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4528 - accuracy: 0.8525 - val_loss: 0.1645 - val_accuracy: 0.9732\n",
      "Epoch 62/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4107 - accuracy: 0.8438\n",
      "Epoch 62: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4353 - accuracy: 0.8447 - val_loss: 0.1536 - val_accuracy: 0.9732\n",
      "Epoch 63/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3990 - accuracy: 0.8438\n",
      "Epoch 63: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4226 - accuracy: 0.8480 - val_loss: 0.1502 - val_accuracy: 0.9766\n",
      "Epoch 64/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4670 - accuracy: 0.8438\n",
      "Epoch 64: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4424 - accuracy: 0.8469 - val_loss: 0.1475 - val_accuracy: 0.9766\n",
      "Epoch 65/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5189 - accuracy: 0.8125\n",
      "Epoch 65: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4509 - accuracy: 0.8447 - val_loss: 0.1452 - val_accuracy: 0.9732\n",
      "Epoch 66/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4631 - accuracy: 0.8438\n",
      "Epoch 66: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8592 - val_loss: 0.1466 - val_accuracy: 0.9699\n",
      "Epoch 67/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4047 - accuracy: 0.8750\n",
      "Epoch 67: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4243 - accuracy: 0.8503 - val_loss: 0.1440 - val_accuracy: 0.9732\n",
      "Epoch 68/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4092 - accuracy: 0.8672\n",
      "Epoch 68: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.8581 - val_loss: 0.1455 - val_accuracy: 0.9732\n",
      "Epoch 69/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4431 - accuracy: 0.8438\n",
      "Epoch 69: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8581 - val_loss: 0.1448 - val_accuracy: 0.9732\n",
      "Epoch 70/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5067 - accuracy: 0.7734\n",
      "Epoch 70: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8503 - val_loss: 0.1384 - val_accuracy: 0.9732\n",
      "Epoch 71/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3411 - accuracy: 0.8906\n",
      "Epoch 71: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4030 - accuracy: 0.8637 - val_loss: 0.1320 - val_accuracy: 0.9766\n",
      "Epoch 72/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.5146 - accuracy: 0.8047\n",
      "Epoch 72: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4421 - accuracy: 0.8413 - val_loss: 0.1354 - val_accuracy: 0.9766\n",
      "Epoch 73/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3997 - accuracy: 0.8438\n",
      "Epoch 73: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3541 - accuracy: 0.8782 - val_loss: 0.1370 - val_accuracy: 0.9732\n",
      "Epoch 74/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8750\n",
      "Epoch 74: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.8615 - val_loss: 0.1348 - val_accuracy: 0.9732\n",
      "Epoch 75/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3752 - accuracy: 0.8672\n",
      "Epoch 75: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3842 - accuracy: 0.8670 - val_loss: 0.1369 - val_accuracy: 0.9699\n",
      "Epoch 76/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4152 - accuracy: 0.8516\n",
      "Epoch 76: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8603 - val_loss: 0.1383 - val_accuracy: 0.9732\n",
      "Epoch 77/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4086 - accuracy: 0.8359\n",
      "Epoch 77: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3839 - accuracy: 0.8570 - val_loss: 0.1302 - val_accuracy: 0.9766\n",
      "Epoch 78/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4034 - accuracy: 0.8594\n",
      "Epoch 78: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8525 - val_loss: 0.1252 - val_accuracy: 0.9766\n",
      "Epoch 79/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3601 - accuracy: 0.8906\n",
      "Epoch 79: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3477 - accuracy: 0.8782 - val_loss: 0.1228 - val_accuracy: 0.9766\n",
      "Epoch 80/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4070 - accuracy: 0.8438\n",
      "Epoch 80: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3466 - accuracy: 0.8804 - val_loss: 0.1216 - val_accuracy: 0.9732\n",
      "Epoch 81/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4136 - accuracy: 0.8438\n",
      "Epoch 81: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3838 - accuracy: 0.8547 - val_loss: 0.1227 - val_accuracy: 0.9732\n",
      "Epoch 82/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4498 - accuracy: 0.8516\n",
      "Epoch 82: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3896 - accuracy: 0.8615 - val_loss: 0.1243 - val_accuracy: 0.9732\n",
      "Epoch 83/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3642 - accuracy: 0.8906\n",
      "Epoch 83: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3645 - accuracy: 0.8838 - val_loss: 0.1245 - val_accuracy: 0.9732\n",
      "Epoch 84/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4136 - accuracy: 0.8594\n",
      "Epoch 84: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3739 - accuracy: 0.8659 - val_loss: 0.1229 - val_accuracy: 0.9732\n",
      "Epoch 85/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8906\n",
      "Epoch 85: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3795 - accuracy: 0.8570 - val_loss: 0.1253 - val_accuracy: 0.9732\n",
      "Epoch 86/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3914 - accuracy: 0.8438\n",
      "Epoch 86: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3984 - accuracy: 0.8525 - val_loss: 0.1255 - val_accuracy: 0.9732\n",
      "Epoch 87/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4358 - accuracy: 0.8516\n",
      "Epoch 87: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.8402 - val_loss: 0.1265 - val_accuracy: 0.9732\n",
      "Epoch 88/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8516\n",
      "Epoch 88: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3536 - accuracy: 0.8693 - val_loss: 0.1251 - val_accuracy: 0.9732\n",
      "Epoch 89/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2728 - accuracy: 0.9297\n",
      "Epoch 89: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3196 - accuracy: 0.8983 - val_loss: 0.1239 - val_accuracy: 0.9732\n",
      "Epoch 90/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3647 - accuracy: 0.8672\n",
      "Epoch 90: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3732 - accuracy: 0.8693 - val_loss: 0.1259 - val_accuracy: 0.9699\n",
      "Epoch 91/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8750\n",
      "Epoch 91: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3555 - accuracy: 0.8771 - val_loss: 0.1189 - val_accuracy: 0.9699\n",
      "Epoch 92/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3362 - accuracy: 0.8672\n",
      "Epoch 92: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3519 - accuracy: 0.8637 - val_loss: 0.1140 - val_accuracy: 0.9732\n",
      "Epoch 93/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4148 - accuracy: 0.8438\n",
      "Epoch 93: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3616 - accuracy: 0.8592 - val_loss: 0.1153 - val_accuracy: 0.9732\n",
      "Epoch 94/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4071 - accuracy: 0.8516\n",
      "Epoch 94: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3590 - accuracy: 0.8704 - val_loss: 0.1196 - val_accuracy: 0.9732\n",
      "Epoch 95/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3123 - accuracy: 0.8906\n",
      "Epoch 95: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3580 - accuracy: 0.8704 - val_loss: 0.1167 - val_accuracy: 0.9732\n",
      "Epoch 96/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8828\n",
      "Epoch 96: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3371 - accuracy: 0.8816 - val_loss: 0.1170 - val_accuracy: 0.9732\n",
      "Epoch 97/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8672\n",
      "Epoch 97: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3351 - accuracy: 0.8827 - val_loss: 0.1159 - val_accuracy: 0.9732\n",
      "Epoch 98/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3918 - accuracy: 0.8672\n",
      "Epoch 98: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3493 - accuracy: 0.8771 - val_loss: 0.1171 - val_accuracy: 0.9732\n",
      "Epoch 99/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4676 - accuracy: 0.8516\n",
      "Epoch 99: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3354 - accuracy: 0.8793 - val_loss: 0.1156 - val_accuracy: 0.9732\n",
      "Epoch 100/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2968 - accuracy: 0.8828\n",
      "Epoch 100: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8793 - val_loss: 0.1129 - val_accuracy: 0.9732\n",
      "Epoch 101/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3784 - accuracy: 0.8594\n",
      "Epoch 101: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3292 - accuracy: 0.8894 - val_loss: 0.1107 - val_accuracy: 0.9732\n",
      "Epoch 102/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2941 - accuracy: 0.8828\n",
      "Epoch 102: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3352 - accuracy: 0.8659 - val_loss: 0.1107 - val_accuracy: 0.9732\n",
      "Epoch 103/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3581 - accuracy: 0.8828\n",
      "Epoch 103: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8927 - val_loss: 0.1104 - val_accuracy: 0.9732\n",
      "Epoch 104/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.9062\n",
      "Epoch 104: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3118 - accuracy: 0.9084 - val_loss: 0.1092 - val_accuracy: 0.9732\n",
      "Epoch 105/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3557 - accuracy: 0.8594\n",
      "Epoch 105: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3346 - accuracy: 0.8737 - val_loss: 0.1065 - val_accuracy: 0.9766\n",
      "Epoch 106/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3269 - accuracy: 0.8984\n",
      "Epoch 106: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3141 - accuracy: 0.8816 - val_loss: 0.1050 - val_accuracy: 0.9766\n",
      "Epoch 107/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2951 - accuracy: 0.9297\n",
      "Epoch 107: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2775 - accuracy: 0.9073 - val_loss: 0.1039 - val_accuracy: 0.9732\n",
      "Epoch 108/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4207 - accuracy: 0.8125\n",
      "Epoch 108: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.8804 - val_loss: 0.1061 - val_accuracy: 0.9732\n",
      "Epoch 109/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8516\n",
      "Epoch 109: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3343 - accuracy: 0.8838 - val_loss: 0.1034 - val_accuracy: 0.9732\n",
      "Epoch 110/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2782 - accuracy: 0.8984\n",
      "Epoch 110: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3016 - accuracy: 0.8883 - val_loss: 0.1046 - val_accuracy: 0.9699\n",
      "Epoch 111/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3340 - accuracy: 0.8828\n",
      "Epoch 111: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3413 - accuracy: 0.8648 - val_loss: 0.1072 - val_accuracy: 0.9699\n",
      "Epoch 112/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4462 - accuracy: 0.8281\n",
      "Epoch 112: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3079 - accuracy: 0.8827 - val_loss: 0.1099 - val_accuracy: 0.9699\n",
      "Epoch 113/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3175 - accuracy: 0.8984\n",
      "Epoch 113: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3195 - accuracy: 0.8838 - val_loss: 0.1115 - val_accuracy: 0.9699\n",
      "Epoch 114/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2960 - accuracy: 0.8906\n",
      "Epoch 114: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3098 - accuracy: 0.8894 - val_loss: 0.1107 - val_accuracy: 0.9699\n",
      "Epoch 115/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2644 - accuracy: 0.8906\n",
      "Epoch 115: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.8849 - val_loss: 0.1100 - val_accuracy: 0.9699\n",
      "Epoch 116/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2515 - accuracy: 0.9297\n",
      "Epoch 116: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3055 - accuracy: 0.8972 - val_loss: 0.1099 - val_accuracy: 0.9699\n",
      "Epoch 117/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2507 - accuracy: 0.9141\n",
      "Epoch 117: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2790 - accuracy: 0.9006 - val_loss: 0.1059 - val_accuracy: 0.9732\n",
      "Epoch 118/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.1885 - accuracy: 0.9531\n",
      "Epoch 118: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2879 - accuracy: 0.8983 - val_loss: 0.1026 - val_accuracy: 0.9732\n",
      "Epoch 119/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2837 - accuracy: 0.9141\n",
      "Epoch 119: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3376 - accuracy: 0.8793 - val_loss: 0.1026 - val_accuracy: 0.9732\n",
      "Epoch 120/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3852 - accuracy: 0.8438\n",
      "Epoch 120: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.8626 - val_loss: 0.1037 - val_accuracy: 0.9766\n",
      "Epoch 121/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2204 - accuracy: 0.9219\n",
      "Epoch 121: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2851 - accuracy: 0.8905 - val_loss: 0.1057 - val_accuracy: 0.9732\n",
      "Epoch 122/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3320 - accuracy: 0.8828\n",
      "Epoch 122: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2855 - accuracy: 0.8972 - val_loss: 0.1067 - val_accuracy: 0.9732\n",
      "Epoch 123/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2555 - accuracy: 0.8984\n",
      "Epoch 123: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3112 - accuracy: 0.8804 - val_loss: 0.1022 - val_accuracy: 0.9732\n",
      "Epoch 124/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9531\n",
      "Epoch 124: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2766 - accuracy: 0.9084 - val_loss: 0.0998 - val_accuracy: 0.9732\n",
      "Epoch 125/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2868 - accuracy: 0.9141\n",
      "Epoch 125: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3119 - accuracy: 0.8894 - val_loss: 0.1007 - val_accuracy: 0.9732\n",
      "Epoch 126/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3620 - accuracy: 0.8594\n",
      "Epoch 126: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8793 - val_loss: 0.1054 - val_accuracy: 0.9732\n",
      "Epoch 127/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2516 - accuracy: 0.9297\n",
      "Epoch 127: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2846 - accuracy: 0.9006 - val_loss: 0.1057 - val_accuracy: 0.9732\n",
      "Epoch 128/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2430 - accuracy: 0.9609\n",
      "Epoch 128: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2687 - accuracy: 0.9151 - val_loss: 0.1022 - val_accuracy: 0.9732\n",
      "Epoch 129/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3868 - accuracy: 0.8906\n",
      "Epoch 129: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2740 - accuracy: 0.9117 - val_loss: 0.0986 - val_accuracy: 0.9732\n",
      "Epoch 130/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3158 - accuracy: 0.8906\n",
      "Epoch 130: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2764 - accuracy: 0.8994 - val_loss: 0.0941 - val_accuracy: 0.9732\n",
      "Epoch 131/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2905 - accuracy: 0.9141\n",
      "Epoch 131: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.8804 - val_loss: 0.0947 - val_accuracy: 0.9732\n",
      "Epoch 132/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4030 - accuracy: 0.8516\n",
      "Epoch 132: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2931 - accuracy: 0.8961 - val_loss: 0.0964 - val_accuracy: 0.9732\n",
      "Epoch 133/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9141\n",
      "Epoch 133: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2838 - accuracy: 0.8883 - val_loss: 0.0976 - val_accuracy: 0.9732\n",
      "Epoch 134/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8672\n",
      "Epoch 134: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3062 - accuracy: 0.8927 - val_loss: 0.1013 - val_accuracy: 0.9732\n",
      "Epoch 135/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3120 - accuracy: 0.8438\n",
      "Epoch 135: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8816 - val_loss: 0.1004 - val_accuracy: 0.9732\n",
      "Epoch 136/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2681 - accuracy: 0.9219\n",
      "Epoch 136: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2644 - accuracy: 0.9028 - val_loss: 0.1016 - val_accuracy: 0.9732\n",
      "Epoch 137/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2989 - accuracy: 0.9141\n",
      "Epoch 137: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2750 - accuracy: 0.9073 - val_loss: 0.1012 - val_accuracy: 0.9732\n",
      "Epoch 138/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3046 - accuracy: 0.8672\n",
      "Epoch 138: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2832 - accuracy: 0.8950 - val_loss: 0.0985 - val_accuracy: 0.9766\n",
      "Epoch 139/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3907 - accuracy: 0.8672\n",
      "Epoch 139: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3375 - accuracy: 0.8782 - val_loss: 0.0986 - val_accuracy: 0.9766\n",
      "Epoch 140/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3063 - accuracy: 0.9062\n",
      "Epoch 140: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2951 - accuracy: 0.9006 - val_loss: 0.1023 - val_accuracy: 0.9699\n",
      "Epoch 141/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2652 - accuracy: 0.8750\n",
      "Epoch 141: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2982 - accuracy: 0.8883 - val_loss: 0.1010 - val_accuracy: 0.9732\n",
      "Epoch 142/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2903 - accuracy: 0.8984\n",
      "Epoch 142: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2966 - accuracy: 0.8838 - val_loss: 0.1002 - val_accuracy: 0.9766\n",
      "Epoch 143/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8984\n",
      "Epoch 143: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2911 - accuracy: 0.8961 - val_loss: 0.1007 - val_accuracy: 0.9732\n",
      "Epoch 144/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8906\n",
      "Epoch 144: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2790 - accuracy: 0.9061 - val_loss: 0.1003 - val_accuracy: 0.9732\n",
      "Epoch 145/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2993 - accuracy: 0.8828\n",
      "Epoch 145: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3016 - accuracy: 0.8927 - val_loss: 0.1040 - val_accuracy: 0.9699\n",
      "Epoch 146/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2547 - accuracy: 0.9062\n",
      "Epoch 146: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2730 - accuracy: 0.8983 - val_loss: 0.0978 - val_accuracy: 0.9732\n",
      "Epoch 147/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.2708 - accuracy: 0.8984\n",
      "Epoch 147: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3099 - accuracy: 0.8849 - val_loss: 0.0944 - val_accuracy: 0.9732\n",
      "Epoch 148/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8828\n",
      "Epoch 148: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2840 - accuracy: 0.8939 - val_loss: 0.0946 - val_accuracy: 0.9766\n",
      "Epoch 149/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.4067 - accuracy: 0.8750\n",
      "Epoch 149: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2973 - accuracy: 0.9006 - val_loss: 0.0972 - val_accuracy: 0.9766\n",
      "Epoch 150/1000\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8906\n",
      "Epoch 150: saving model to model/gesture_classifier.keras\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2748 - accuracy: 0.9006 - val_loss: 0.0968 - val_accuracy: 0.9766\n",
      "Epoch 150: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4b1c594490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model with inference optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 911us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        47\n",
      "         2.0       1.00      1.00      1.00       106\n",
      "         3.0       0.92      0.99      0.95        74\n",
      "         4.0       0.99      0.92      0.95        72\n",
      "\n",
      "    accuracy                           0.98       299\n",
      "   macro avg       0.98      0.98      0.98       299\n",
      "weighted avg       0.98      0.98      0.98       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "[1.5744225e-05 1.9168633e-04 2.7550471e-03 9.3604982e-01 6.0987648e-02]\n",
      "3\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "i = 678\n",
    "predict_result = model.predict(np.array([x_data[i]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "print(y_data[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
